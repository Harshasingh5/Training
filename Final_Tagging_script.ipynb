{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Tagging_script.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "vWDfGanB2csr"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshasingh5/Training/blob/master/Final_Tagging_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4pAeGSADWt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjFoDjxD2YFo",
        "colab_type": "text"
      },
      "source": [
        "#Cleaning data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqDE-iOY2g1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# import spacy\n",
        "import re\n",
        "import string\n",
        "#upload flashtext_me_12 file first\n",
        "from flashtext_me_12 import KeywordProcessor\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "base_directory = \"/content/drive/My Drive/long_search_attribute_identify/NOMBRENUMERUS/\"\n",
        " ##to tokenise \n",
        "# nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "numb = re.compile(r'\\d[x|X|.|/|\"|*|#|,|^|:|<|>|;|\\s|\\-|\\d]*')\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def regex_clean(key):\n",
        "    key.translate(str.maketrans(\"\",\"\", string.punctuation)).strip()\n",
        "    return key\n",
        "\n",
        "def read_file(filename):\n",
        "    kv_dict_file = base_directory+filename\n",
        "    kv_dict = pd.read_csv(kv_dict_file, names=['FK_IM_SPEC_OPTIONS_DESC' ,'FK_IM_SPEC_MASTER_DESC'] )\n",
        "    return kv_dict\n",
        "\n",
        "def lemmatize(row_list):\n",
        "    data = \" \".join([wnl.lemmatize(word) for word in word_tokenize(row_list)])\n",
        "    return data\n",
        "\n",
        "\n",
        "def clean_searches(filename):\n",
        "    searches_file = base_directory+filename\n",
        "    searches_d = pd.read_csv(searches_file, names=['searches'], skiprows=1)\n",
        "    print(searches_d)\n",
        "    #fill NA with blank\n",
        "    searches_d = searches_d.fillna(\"\")\n",
        "    \n",
        "    ##lower case\n",
        "    searches_d['searches'] = searches_d['searches'].str.lower().apply(lambda x: lemmatize(x)).str.replace(numb,'NOMBRENUMERUS').replace(\"\\n\", \" \").replace(\"\\t\", \" \").str.translate(str.maketrans(\"\",\"\", string.punctuation)).str.strip()\n",
        "    ##drop duplicates\n",
        "    searches = searches_d.drop_duplicates()\n",
        "        \n",
        "    return searches\n",
        "\n",
        "\n",
        "def clean_ISQ_kv_dict(filename, key_name=None):\n",
        "    kv_dict_F = pd.DataFrame()\n",
        "    kv_dict_file = base_directory+filename\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "    for kv_dict in pd.read_csv(kv_dict_file, names=['mcat_org_names','FK_IM_SPEC_MASTER_DESC','FK_IM_SPEC_OPTIONS_DESC'] , chunksize=3000000,  error_bad_lines=False, encoding=\"ISO-8859â€“1\"):\n",
        "        if key_name:\n",
        "            kv_dict['FK_IM_SPEC_OPTIONS_DESC'] = key_name\n",
        "\n",
        "        #fill NA with blank\n",
        "        kv_dict = kv_dict.fillna(\"\")\n",
        "        print(\"--- %s seconds to read file and fillna---\" % (time.time() - start_time))\n",
        "        print(\"kv_dict:--------------\", kv_dict)\n",
        "\n",
        "        ##lower case\n",
        "        kv_dict['FK_IM_SPEC_MASTER_DESC'] = kv_dict['FK_IM_SPEC_MASTER_DESC'].str.lower().apply(lambda x: lemmatize(x)).str.replace(numb,'NOMBRENUMERUS ').str.translate(str.maketrans(\"\",\"\", string.punctuation)).str.replace(\"\\n\", \" \").str.replace(\"\\t\", \" \").str.strip()\n",
        "        kv_dict['FK_IM_SPEC_OPTIONS_DESC'] = kv_dict['FK_IM_SPEC_OPTIONS_DESC'].str.lower().apply(lambda x: lemmatize(x)).str.replace(numb,'NOMBRENUMERUS ').str.translate(str.maketrans(\"\",\"\", string.punctuation)).str.replace(\"\\n\", \" \").str.replace(\"\\t\", \" \").str.strip()\n",
        "       \n",
        "        print(\"--- %s seconds To number strip extra spaces---\" % (time.time() - start_time))\n",
        "        print(\"num kv_dict: --------------------------\",kv_dict)\n",
        "\n",
        "        ##drop duplicates\n",
        "        kv_dict = kv_dict.drop_duplicates()   \n",
        "        kv_dict_F = kv_dict_F.append(kv_dict)\n",
        "        print(\"kv_dict_ dropped-----------------------------------------------------------------------------------------------------------------::::\",kv_dict)\n",
        "\n",
        "        with open('clean_data_split_10JULY.csv', 'a') as f:\n",
        "            kv_dict.to_csv(f, header=False , columns=['FK_IM_SPEC_MASTER_DESC','FK_IM_SPEC_OPTIONS_DESC'])\n",
        "        # print(\"kv_dict_F-----------------------------------------------------------------------------------------------------------------::::\",kv_dict_F)\n",
        "    return kv_dict  \n",
        "\n",
        "def clean_searches(filename):\n",
        "    searches_file = base_directory+filename\n",
        "    searches_d = pd.read_csv(searches_file, names=['searches'], skiprows=1)\n",
        "    print(searches_d)\n",
        "    #fill NA with blank\n",
        "    searches_d = searches_d.fillna(\"\")\n",
        "    \n",
        "    ##lower case\n",
        "    searches_d['searches'] = searches_d['searches'].str.lower().apply(lambda x: lemmatize(x)).str.replace(numb,'NOMBRENUMERUS ').replace(\"\\n\", \" \").replace(\"\\t\", \" \").str.translate(str.maketrans(\"\",\"\", string.punctuation)).str.strip()\n",
        "    \n",
        "    ##drop duplicates\n",
        "    searches = searches_d.drop_duplicates()\n",
        "    return searches\n",
        "\n",
        "\n",
        "# searches_15k  clean_searches\n",
        "isq_kv = clean_ISQ_kv_dict(\"brand_list.csv\", \"brand\")\n",
        "print(\"tada!!\", isq_kv)\n",
        "isq_kv.to_csv(\"brand_list_clean.csv\", index=False , columns=['FK_IM_SPEC_MASTER_DESC','FK_IM_SPEC_OPTIONS_DESC'])\n",
        "\n",
        "isq_kv = clean_searches(\"searches_15k.csv\")\n",
        "isq_kv.to_csv(\"searches_15k_clean.csv\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak0bC_np3SyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Write the csv directly into google drive\n",
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "# update_file = 'searches_15k_clean.csv'\n",
        "update_file = 'brand_list_clean.csv'\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "    file_metadata = {\n",
        "      'name': name,\n",
        "      'mimeType': 'application/octet-stream'\n",
        "     }\n",
        "\n",
        "    media = MediaFileUpload(path, mimetype='application/octet-stream',resumable=True)\n",
        "\n",
        "    created = drive_service.files().create(body=file_metadata,media_body=media,fields='id').execute()\n",
        "\n",
        "    print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "    return created\n",
        "save_file_to_drive(update_file, update_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWDfGanB2csr",
        "colab_type": "text"
      },
      "source": [
        "#Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGJUo8b5EB4",
        "colab_type": "text"
      },
      "source": [
        "**Time Taken by each cell:**\n",
        "\n",
        "1.   Loading Data: 12.366s\n",
        "2.   ISQ data to trie ds: 664.517s   RAM:7.3GB\n",
        "3.   MCAT data to trie ds:  32.19s   RAM:0.22GB\n",
        "4.   City data to trie ds:5.59s     RAM:0.03\n",
        "5.   Tagging 15k searches: 3.64s    \n",
        "6.   Writing in file:   RAM for 5 and 6: 0.02\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iZq-OoLkPh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# import spacy\n",
        "import re\n",
        "import string\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2YxcOUkW-MJ",
        "colab_type": "code",
        "outputId": "325873a6-370a-4177-deaa-3395950b6fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#if cleaned data exists\n",
        "base_directory = \"/content/drive/My Drive/long_search_attribute_identify/NOMBRENUMERUS/\"\n",
        "# base_directory = \"/content/drive/My Drive/NOMBRENUMERUS/\"\n",
        "def read_files(filename):\n",
        "    kv_dict_file = base_directory+filename\n",
        "    kv_dict = pd.read_csv(kv_dict_file, names=['FK_IM_SPEC_OPTIONS_DESC' ,'FK_IM_SPEC_MASTER_DESC'])\n",
        "    return kv_dict\n",
        "\n",
        "def read_files_isqfreq(filename):\n",
        "    kv_dict_file = base_directory+filename\n",
        "    kv_dict = pd.read_csv(kv_dict_file, names=['FK_IM_SPEC_OPTIONS_DESC' ,'FK_IM_SPEC_MASTER_DESC', 'size'])\n",
        "    return kv_dict\n",
        "\n",
        "mcat_kv = read_files(\"clean_mcat_name_all.csv\")\n",
        "mcatalt_kv = read_files(\"mcat_alt_names_list_clean.csv\")\n",
        "brand_kv = read_files(\"brand_list_clean.csv\")\n",
        "isq_kv = read_files_isqfreq(\"grouped_all_isq.csv\")\n",
        "city_kv =  read_files(\"city.csv\")\n",
        "isq_kv = isq_kv.drop_duplicates()\n",
        "\n",
        "searches_file = base_directory+\"searches_15k_clean.csv\"\n",
        "# searches_file =\"searches_15k_clean.csv\"\n",
        "searches = pd.read_csv(searches_file, names=['searches'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF43OrxTXHBV",
        "colab_type": "code",
        "outputId": "c4d844cf-f91f-4081-a0fe-62374777914d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "##For isqs\n",
        "from flashtext_me_12 import KeywordProcessor\n",
        "%time\n",
        "exception_list = [\"and\",\"\", \"all\", \"NOMBRENUMERUS\",\"by\",\"supplier\", \"buyer\", \"any\", \"on\", \"to\", \"in\", \"for\", \"of\",\"with\",\"and\",\"are\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
        "kp = KeywordProcessor()\n",
        "for index,row in isq_kv.iterrows():\n",
        "    if str(row['FK_IM_SPEC_OPTIONS_DESC']) not in exception_list:\n",
        "        kp.add_keyword(str(row['FK_IM_SPEC_OPTIONS_DESC']), ( str(row['FK_IM_SPEC_MASTER_DESC']+\"/\"+str(row['size'])), str(row['FK_IM_SPEC_OPTIONS_DESC'])))\n",
        "    # else:\n",
        "        # print(row)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 Âµs, sys: 0 ns, total: 4 Âµs\n",
            "Wall time: 9.06 Âµs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvWuIKe1XXo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##For mcat names\n",
        "for index,row in mcatalt_kv.iterrows():\n",
        "    if str(row['FK_IM_SPEC_OPTIONS_DESC']) not in exception_list:\n",
        "        kp.add_keyword(str(row['FK_IM_SPEC_OPTIONS_DESC']), (str(row['FK_IM_SPEC_MASTER_DESC']), str(row['FK_IM_SPEC_OPTIONS_DESC'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpbih5f05VUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##For mcat alt names\n",
        "for index,row in mcat_kv.iterrows():\n",
        "    if str(row['FK_IM_SPEC_OPTIONS_DESC']) not in exception_list:\n",
        "        kp.add_keyword(str(row['FK_IM_SPEC_OPTIONS_DESC']), (str(row['FK_IM_SPEC_MASTER_DESC']), str(row['FK_IM_SPEC_OPTIONS_DESC'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMnBZ7i8XYbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###for city name\n",
        "for index,row in city_kv.iterrows():\n",
        "    if str(row['FK_IM_SPEC_OPTIONS_DESC']) not in exception_list:\n",
        "        kp.add_keyword(str(row['FK_IM_SPEC_OPTIONS_DESC']), (str(row['FK_IM_SPEC_MASTER_DESC']), str(row['FK_IM_SPEC_OPTIONS_DESC'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3eV4dOR5cyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###for brand name\n",
        "for index,row in brand_kv.iterrows():\n",
        "    if str(row['FK_IM_SPEC_OPTIONS_DESC']) not in exception_list:\n",
        "        kp.add_keyword(str(row['FK_IM_SPEC_OPTIONS_DESC']), (str(row['FK_IM_SPEC_MASTER_DESC']), str(row['FK_IM_SPEC_OPTIONS_DESC'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCgHjgD6Xf-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Tagging searches\n",
        "searches_kv = [(kp.extract_keywords(str(row['searches'])), row['searches']) for index, row in searches.iterrows()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKXbzgeeYE4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Write the tagged searches in csv\n",
        "import pandas as pd\n",
        "\n",
        "update_file = 'Tagged_searches_13Aug.csv'\n",
        "\n",
        "for search in searches_kv:\n",
        "    news = []  \n",
        "    news.append(search[1])\n",
        "    for sear in search[0]:\n",
        "        testdf = pd.DataFrame(sear, columns=['isq','value'])\n",
        "        isq = testdf['value'].unique()\n",
        "        for each in isq:\n",
        "            newdf = testdf[testdf['value'] == each]\n",
        "            news.append(each)\n",
        "            news.append(list(newdf['isq'].unique()))\n",
        "    # print(news)\n",
        "    with open(update_file, 'a') as f:\n",
        "        pd.DataFrame([news]).to_csv(f, header=False,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6kVXQ1UYcfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Write the csv directly into google drive\n",
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "# update_file = 'searches_15k_clean.csv'\n",
        "# update_file = 'WithFreq_tagged_searches.csv'\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "    file_metadata = {\n",
        "      'name': name,\n",
        "      'mimeType': 'application/octet-stream'\n",
        "     }\n",
        "\n",
        "    media = MediaFileUpload(path, mimetype='application/octet-stream',resumable=True)\n",
        "\n",
        "    created = drive_service.files().create(body=file_metadata,media_body=media,fields='id').execute()\n",
        "\n",
        "    print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "    return created\n",
        "save_file_to_drive(update_file, update_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIKrxxcPDWkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjvHmD01DW36",
        "colab_type": "text"
      },
      "source": [
        "# Test/Rough\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg6MrRPMb1Fu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "546fa41d-256f-43d7-9637-88d7b7c764a9"
      },
      "source": [
        "import re\n",
        "numb = re.compile(r'\\d[x|X|.|/|\"|*|#|,|^|:|<|>|;|\\s|\\-|\\d]*')\n",
        "# \"s hfj\".str.replace(numb, \"AOKAY\")\n",
        "re.sub(r'\\d[x|X|.|/|\"|*|#|,|^|:|<|>|;|\\s|\\-|\\d]*' ,\"AOKAY\", \"tv s\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tv AOKAYs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOCx3cZnDa3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##For isqs\n",
        "from flashtext_me_13Aug import KeywordProcessor\n",
        "%time\n",
        "exception_list = [\"and\",\"\", \"all\", \"NOMBRENUMERUS\",\"by\",\"supplier\", \"buyer\", \"any\", \"on\", \"to\", \"in\", \"for\", \"of\",\"with\",\"and\",\"are\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
        "kn = KeywordProcessor()\n",
        "for index,row in isq_kv.iterrows():\n",
        "    if str(row['FK_IM_SPEC_OPTIONS_DESC']) not in exception_list:\n",
        "        kn.add_keyword(str(row['FK_IM_SPEC_OPTIONS_DESC']), ( str(row['FK_IM_SPEC_MASTER_DESC']+\"/\"+str(row['size'])), str(row['FK_IM_SPEC_OPTIONS_DESC'])))\n",
        "    # else:\n",
        "        # print(row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpWtuYX7EcDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "searches_kv = [(kn.extract_keywords(str(row['searches'])), row['searches']) for index, row in searches.iterrows()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klh0wVr6E9vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# kn.extract_keywords(\"currency note holy number of NOMBRENUMERUS\")\n",
        "kn.extract_keywords(\"tv apache rtr NOMBRENUMERUS spare part\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU9hbVSO8HBF",
        "colab_type": "code",
        "outputId": "3143d161-bced-49c2-8496-c5b86b5e72fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "isq_kv.loc[isq_kv.FK_IM_SPEC_OPTIONS_DESC.str.contains(\"NOMBRENUMERUSin\")]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FK_IM_SPEC_OPTIONS_DESC</th>\n",
              "      <th>FK_IM_SPEC_MASTER_DESC</th>\n",
              "      <th>size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [FK_IM_SPEC_OPTIONS_DESC, FK_IM_SPEC_MASTER_DESC, size]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chGCmDaH0NQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/WithFreq_tagged_searches.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz7Va07A0iXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(kp.extract_keywords('NOMBRENUMERUS inch'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnlpdXVv2KLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# isq_kv = pd.read_csv('/content/drive/My Drive/long_search_attribute_identify/ISQ_kv_All.csv', error_bad_lines=False, encoding=\"ISO-8859â€“1\", names=['FK_IM_SPEC_OPTIONS_DESC' ,'FK_IM_SPEC_MASTER_DESC'])\n",
        "isq_kv = pd.read_csv('/content/drive/My Drive/long_search_attribute_identify/NOMBRENUMERUS/clean_ISQ_all_withDuplicates.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLSPVsH5DV8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}